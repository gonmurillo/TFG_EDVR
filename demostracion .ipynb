{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estudio de funcionamiento de EDVR, herramienta de super resolución de vídeos\n",
    "## TFG del Grado en Ingeniería Informática en la Universidad de Burgos. Curso 2020-21\n",
    "\n",
    "Realizado por:\n",
    "*  Gonzalo Murillo Montes \n",
    "\n",
    "Tutores:\n",
    "*  Pedro Latorre Carmona\n",
    "*  César Ignacio García Osorio\n",
    "\n",
    "```bash\n",
    "@misc{wang2020basicsr,\n",
    "  author =       {Xintao Wang and Ke Yu and Kelvin C.K. Chan and\n",
    "                  Chao Dong and Chen Change Loy},\n",
    "  title =        {BasicSR},\n",
    "  howpublished = {\\url{https://github.com/xinntao/BasicSR}},\n",
    "  year =         {2020}\n",
    "}\n",
    "```\n",
    "Xintao Wang, Kelvin C.K. Chan, Ke Yu, Chao Dong, &amp; Chen Change Loy. (2019, May 7). EDVR: Video Restoration with Enhanced Deformable Convolutional Networks [PDF]. Ithaca, New York: Cornell University."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ÍNDICE**   \n",
    "1. <a id=\"index\"></a>[¿NTIRE19 CHALLENGE?](#id1)\n",
    "\n",
    "\n",
    "2. <a id=\"index\"></a>[¿QUÉ ES EDVR?](#id2)\n",
    "\n",
    "\n",
    "3. <a id=\"index\"></a>[PASOS PREVIOS](#id3)\n",
    "\n",
    "\n",
    "4. <a id=\"index\"></a>[DATASETS](#id4)\n",
    "\n",
    "    4.1. <a id=\"index\"></a>[REDS](#id5)\n",
    "    \n",
    "    4.2. <a id=\"index\"></a>[ Vimeo-90k](#id6)\n",
    "    \n",
    "    \n",
    "5. <a id=\"index\"></a>[PASOS PREVIOS AL TRAIN](#id7)    \n",
    "\n",
    "\n",
    "6. <a id=\"index\"></a>[PASOS PREVIOS AL TEST](#id8)\n",
    "\n",
    "\n",
    "7. <a id=\"index\"></a>[TRAIN AND TEST](#id9)\n",
    "\n",
    "    7.1. <a id=\"index\"></a>[TRAIN 1 GPU](#id10)\n",
    "        \n",
    "    7.2. <a id=\"index\"></a>[TEST 1 GPU](#id11)\n",
    "    \n",
    "    7.3. <a id=\"index\"></a>[TEST 8 GPU](#id12)\n",
    "    \n",
    "    7.4. <a id=\"index\"></a>[TEST 1 GPU Slurm](#id13)\n",
    "    \n",
    "    \n",
    "8. <a id=\"index\"></a>[EJECUCIÓN](#id14)    \n",
    "\n",
    "\n",
    "9. <a id=\"index\"></a>[DEMOSTRACIÓN](#id15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ¿NTIRE19 CHALLENGE?<a name=\"id1\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "New Trends in Image Restoration and Enhancement workshop and challenges on image and video restoration and enhancement.\n",
    "Proponen diversos retos en las áreas de la restauración de imágenes y vídeos y los participantes compiten para obtener los mejores resultados.\n",
    "\n",
    "EDVR es la solución ganadora del NTIRE19 Challenge en la categoría de super resolución de vídeos, centrada en dos aspectos:\n",
    "\n",
    "* Alienación de múltiples frames con mucho movimiento.\n",
    "* Fusión de frames con distintos movimientos y partes borrosas. \n",
    "\n",
    "EDVR ganó en las 4 pruebas relacionadas con vídeos con amplio margen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ¿QUÉ ES EDVR?<a name=\"id2\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "EDVR es el acrónimo de Enhanced Deformable convolutions Video Restoration, es una herramienta contenida en BasicSR, centrada en la super resolución y desemborronamiento de vídeos.\n",
    "\n",
    "Está basada en dos principios el PCD (Pyramid,\n",
    "Cascading and Deformable convolutions) y el TSA (Temporal and Spatial Attention)\n",
    "\n",
    "* PCD: usa convoluciones deformables para agrupar píxeles cercanos, usando una estructura piramidal invertida empezando a pequeña escala y progresivamente aumentando, junto a esto se aplica un efecto cascada para mejorar resultados. \n",
    "* TSA: es un módulo de fusión que agrega información comparando frames con sus anteriores y posteriores, toda esa información luego se usa en todos los frames.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ejemplos/FrameworkEDVR.PNG\">\n",
    "\n",
    "### Estructura de EDVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PASOS PREVIOS<a name=\"id3\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos estos pasos pueden seguirse para descargar y poder usar el [repositorio original de EDVR](https://github.com/xinntao/EDVR). Si no se quieren descargar todos los datasets puede descargar mi repositorio en dentro del original y comprobar los resultados. En el apartado de [EJECUCIÓN](#id14) se exponen las dos opciones a la hora de realizar la prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder ejecutar EDVR es necesario cumplir los siguientes requisitos:\n",
    "\n",
    "+ Tener Python => 3.7\n",
    "\n",
    "+ PyTorch >= 1.3\n",
    "\n",
    "+ NVIDIA GPU compatible con CUDA\n",
    " \n",
    "+ Clonar el repositorio\n",
    "\n",
    "Una vez cumplidos ejecutamos estas dos casillas y comprobará que cumple los requisitos e instalaran los archivos que falten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " !pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " !python ../setup.py develop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASETS<a name=\"id4\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las pruebas se han usado 2 datasets, REDS dataset y Vimeo-90k dataset. Debido a que ambos datasets ocupan mucho, no están en el repositorio, pero aquí están los pasos para descargarlos y poder ejecutar EDVR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REDS<a name=\"id5\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "Es el dataset oficial del NTIRE 2019 Y NTIRE 2020 Challenge, acrónimo de REalistic and Dynamic Scenes está centrado en el desemborronado y super resolución de vídeos. Tiene diferentes apartados con diferentes situaciones, imágenes borrosas, borrosas y comprimidas, en baja resolución y borrosas y en baja resolución.\n",
    "\n",
    "```bash\n",
    "@InProceedings{Nah_2019_CVPR_Workshops_REDS,\n",
    "  author = {Nah, Seungjun and Baik, Sungyong and Hong, Seokil and Moon, Gyeongsik and Son, Sanghyun and Timofte, Radu and Lee, Kyoung Mu},\n",
    "  title = {NTIRE 2019 Challenge on Video Deblurring and Super-Resolution: Dataset and Study},\n",
    "  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},\n",
    "  month = {June},\n",
    "  year = {2019}\n",
    "}\n",
    "```\n",
    "REDS se puede obtener [aquí](https://seungjunnah.github.io/Datasets/reds.html). \n",
    "Aquí se nos explica brevemente el dataset y se nos ofrecen dos tipos de descarga, mediante Google Drive y SNU CVLab server. Una vez descomprimido el dataset ocupa 291 GB\n",
    "\n",
    "La opción que he usado es Google Drive, a veces Google bloquea el acceso a los ficheros, con algo de paciencia se consiguen todos, la otra opción no conseguí que funcionase en mi caso. También en esta web hay un script de Python, pero  por lo expuesto, tampoco conseguí que descargase las carpetas comprimidas del dataset.\n",
    "\n",
    "Una vez descargadas todas las carpetas hay que extraer las imágenes, el dataset contiene las imágenes en baja resolución y las originales. Los path pueden cambiar y habría que modificar los archivos  .yml contenidos en la carpeta options, en nuestro caso tanto los contenidos en train/EDVR y test/EDVR referentes a este dataset, más adelante se explicará el contenido de estos archivos con un ejemplo.\n",
    "\n",
    "Una vez hecho esto ejecutamos un scipt de Python para comprobar que todo está bien, solo habrá que modificar en el script los path al dataset. /tests/test_reds_dataset.py\n",
    "\n",
    "Con esto ya tendríamos REDS preparado para trabajar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vimeo-90k<a name=\"id6\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "Dataset creado original mente para el proyecto Video Enhancement with Task-Oriented Flow, consistente en 89.800 clips de vídeo procedentes de vimeo.com, una de sus principales funciones entre otra es servir para la super resolución de vídeos. La versión que se utiliza consta de 91.701 secuencias de 7 frames con una resolución fija.\n",
    "\n",
    "\n",
    "La cita pertenece a el trabajo para el que se creó el dataset, no sé si debería mencionarlo o no?¿\n",
    "\n",
    "```\n",
    " @article{xue2019video,\n",
    "  title={Video Enhancement with Task-Oriented Flow},\n",
    "  author={Xue, Tianfan and Chen, Baian and Wu, Jiajun and Wei, Donglai and Freeman, William T},\n",
    "  journal={International Journal of Computer Vision (IJCV)},\n",
    "  volume={127},\n",
    "  number={8},\n",
    "  pages={1106--1125},\n",
    "  year={2019},\n",
    "  publisher={Springer}\n",
    "}\n",
    "```\n",
    "Vimeo-90k se puede obtener [aquí](http://toflow.csail.mit.edu/).\n",
    "\n",
    "Al final de la web se nos presentan diferentes versiones del dataset, en mi caso se usa el último, The original training + test set (82GB). Una vez descomprimido y con las imágenes en baja resolución generadas ocupa 184 GB.\n",
    "\n",
    "Una vez descargado y extraído obtenemos las imágenes en alta resolución solamente, ahora tenemos que crear las imágenes en baja resolución. Para ello usaremos un script de Matlab. Este script se encuentra dentro de la carpeta /scripts/matlab_scripts y con el nombre de generate_LR_Vimeo90K.m\n",
    "\n",
    "Es posible que se tenga que modificar el path dentro del script.\n",
    "\n",
    "Una vez creadas las imágenes en baja resolución igual que en REDS hay un script de Python para comprobar que todo está bien.\n",
    "Situado en /tests/test_vimeo90k_dataset.py\n",
    "\n",
    "Con esto ya tendríamos Vimeo-90k preparado para trabajar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PASOS PREVIOS AL TRAIN <a name=\"id7\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "name: 102_EDVR_M_x4_SR_REDS_600k_B4G8_valREDS4_101pretrain_wandb\n",
    "# es el nombre de la ejecución, que puede cambiarse \n",
    "model_type: EDVRModel\n",
    "# el modelo siempre será el mismo ya que solo trabajamos con EDVR en BasicSR\n",
    "scale: 4\n",
    "# es la escala de la salida respecto a la entrada, el upsampling ratio.\n",
    "num_gpu: 8 \n",
    "# en todas mis ejecuciones el número de Gpu es una por mis limitaciones hardware, que se indica por parámetro, con 0 se usa la Cpu\n",
    "manual_seed: 10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "datasets:\n",
    "  train:\n",
    "    name: REDS\n",
    "    # el nombre del dataset\n",
    "    type: REDSDataset\n",
    "    # es el tipo de dataset que se usa:\n",
    "    # 1. subfolder (clip) name; 2. frame number; 3. image shape\n",
    "    #  000 100 (720,1280,3)\n",
    "    dataroot_gt: datasets/REDS/train_sharp/train_sharp\n",
    "    # path a las imágenes originales\n",
    "    dataroot_lq: datasets/REDS/train_sharp_bicubic/train/train_sharp_bicubic/X4\n",
    "    # path a las imágenes en baja calidad\n",
    "    dataroot_flow: ~\n",
    "    meta_info_file: basicsr/data/meta_info/meta_info_REDS_GT.txt\n",
    "    # selección de sub-carpetas con las que se ejecutara EDVR\n",
    "    val_partition: REDS4  \n",
    "   \n",
    "    io_backend:\n",
    "      type: disk\n",
    "    # hay tres opciones para la ejecución disk, LMDB o memcached, solo se ha usado disk para los experimentos\n",
    "    \n",
    "    num_frame: 5\n",
    "    # número de frames\n",
    "    gt_size: 256\n",
    "    # tamaño del Ground-Truth \n",
    "    interval_list: [1]\n",
    "    random_reverse: false\n",
    "    use_flip: true\n",
    "    # usa la rotación de 180 grados\n",
    "    use_rot: true\n",
    "    # usa la rotación de 90 grados \n",
    "    \n",
    "    use_shuffle: true\n",
    "    # se baraja \n",
    "    num_worker_per_gpu: 3\n",
    "    # número de lecturas de cada GPU\n",
    "    batch_size_per_gpu: 4\n",
    "    # tamaño total de la ejecución\n",
    "    dataset_enlarge_ratio: 200\n",
    "    # el ratio de ampliación del dataset \n",
    "    prefetch_mode: ~\n",
    "\n",
    "  val:\n",
    "    name: REDS4\n",
    "    # nombre del dataset de validación\n",
    "    type: VideoTestDataset\n",
    "    # es el tipo de dataset que se usa:\n",
    "    # 1. clip name; 2. frame number; 3. number of frames; 4. tamaño de la imagen \n",
    "    #  00001/0001 7 (256,448,3)\n",
    "    dataroot_gt: datasets/REDS/train_sharp\n",
    "    # path a las imágenes originales\n",
    "    dataroot_lq: datasets/REDS/train_sharp_bicubic\n",
    "    # path a las imágenes en baja calidad\n",
    "    meta_info_file: basicsr/data/meta_info/meta_info_REDS4_test_GT.txt\n",
    "    # selección de sub-carpetas con las que se ejecutara EDVR\n",
    "    io_backend:\n",
    "      type: disk\n",
    "    # hay tres opciones para la ejecución disk, LMDB o memcached, solo se ha usado disk para los experimentos\n",
    "    \n",
    "    cache_data: false\n",
    "    num_frame: 5\n",
    "    # número de \n",
    "    padding: reflection_circle\n",
    "    # replicate o reflection_circle, son dos técnicas para conseguir que durante el procesamiento el tamaño de las \n",
    "    # imágenes no cambien.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "network_g:\n",
    "  type: EDVR\n",
    "  # tipo de arquitectura que se usa, solo usaremos EDVR\n",
    "  num_in_ch: 3\n",
    "  # número de canales de entradas de inputs\n",
    "  num_out_ch: 3\n",
    "  # número de canales de salidas de inputs \n",
    "  num_feat: 64\n",
    "  # número de canales intermedios \n",
    "  num_frame: 5\n",
    "  # número de frames\n",
    "  deformable_groups: 8\n",
    "  num_extract_block: 5\n",
    "  num_reconstruct_block: 10\n",
    "  center_frame_idx: ~\n",
    "  hr_in: false\n",
    "  with_predeblur: false\n",
    "  # tenemos la opción de activar o desactivar la opción de desemborronado previo\n",
    "  with_tsa: true\n",
    "  # tenemos la opción de activar o desactivar la opción de TSA de fusión de frames\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "path:\n",
    "  pretrain_network_g: experiments/101_EDVR_M_x4_SR_REDS_woTSA_600k_B4G8_valREDS4_wandb/models/net_g_600000.pth\n",
    "  # path al modelo pre-entrenado\n",
    "  strict_load_g: false\n",
    "  # si solo queremos cargar el modelo pre-entrenado\n",
    "  resume_state: ~\n",
    "  # si una ejecución  se interrumpe, podemos continuar\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```yaml\n",
    "train:\n",
    "  optim_g:\n",
    "    type: Adam\n",
    "    # tipo de optimizador\n",
    "    lr: !!float 4e-4\n",
    "    # ratio de aprendizaje \n",
    "    weight_decay: 0\n",
    "    betas: [0.9, 0.99]\n",
    "    # beta1 and beta2 para Adam\n",
    "\n",
    "  scheduler:\n",
    "    type: CosineAnnealingRestartLR\n",
    "    # tipo de programador\n",
    "    periods: [50000, 100000, 150000, 150000, 150000]\n",
    "    # periodos de alineamiento de coseno \n",
    "    restart_weights: [1, 1, 1, 1, 1]\n",
    "    # pesos de reinicio del alineamiento de coseno \n",
    "    eta_min: !!float 1e-7\n",
    "    # tasa mínima de aprendizaje   \n",
    "\n",
    "  total_iter: 600000\n",
    "  # número de interacciones total \n",
    "  warmup_iter: -1 \n",
    "  # pruebas de calentamiento, -1 es ninguna\n",
    "  tsa_iter: 50000\n",
    "  # número de interacciones en modo tsa\n",
    "  dcn_lr_mul: 1\n",
    "\n",
    "  pixel_opt:\n",
    "    type: CharbonnierLoss\n",
    "    # tipo de pérdida \n",
    "    loss_weight: 1.0\n",
    "    # peso de la pérdida\n",
    "    reduction: sum\n",
    "    # modo de reducción\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "val:\n",
    "  val_freq: !!float 5e3\n",
    "  # frecuencia de validación \n",
    "  save_img: false\n",
    "  # si se guardan las imágenes durante la validación\n",
    "\n",
    "  metrics:\n",
    "  # métricas extra que calculan el PSNR(Peak Signal-to-Noise Ratio)\n",
    "    psnr: \n",
    "      type: calculate_psnr\n",
    "      crop_border: 0\n",
    "      test_y_channel: false\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "logger:\n",
    "  print_freq: 100\n",
    "  # frecuencia de logger \n",
    "  save_checkpoint_freq: !!float 5e3\n",
    "  # la frecuencia para guardar puntos de control\n",
    "  use_tb_logger: true\n",
    "  # si se usa tensorboard logger\n",
    "  wandb:\n",
    "  # si se usa wandb logger\n",
    "    project: ~\n",
    "    resume_id: ~\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` yaml\n",
    "dist_params:\n",
    "# solo se usa con slurm training \n",
    "  backend: nccl\n",
    "  port: 29500\n",
    "\n",
    "find_unused_parameters: true\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PASOS PREVIOS AL TEST<a name=\"id8\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero es seleccionar los datasets o imágenes con las que se va a trabajar, si se quisiese usar un vídeo primero habría que generar la secuencia de frames y las imágenes en baja calidad.\n",
    "\n",
    "Una vez hecho esto hay que crear un fichero .yml con las siguientes especificaciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "name: EDVR_L_x4_REDS_SRblur_official\n",
    "# es el nombre de la ejecución, que puede cambiarse \n",
    "model_type: EDVRModel\n",
    "# el modelo siempre será el mismo ya que solo trabajamos con EDVR en BasicSR\n",
    "scale: 4\n",
    "# es la escala de la salida respecto a la entrada, el upsampling ratio.\n",
    "num_gpu: 4\n",
    "# en todas mis ejecuciones el número de Gpu es una por mis limitaciones hardware, que se indica por parámetro, on 0 se usa la cpu\n",
    "manual_seed: 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "datasets:\n",
    "  test:\n",
    "    name: REDS4\n",
    "    # el nombre del dataset\n",
    "    type: VideoTestDataset\n",
    "    # es el tipo de dataset que se usa, depende de la estructura de los dataset, en nuestro caso se usan dos:\n",
    "    # video_test_dataset: \n",
    "    #                      dataroot\n",
    "    #                      ├── subfolder1\n",
    "    #                           ├── frame000\n",
    "    #                           ├── frame001\n",
    "    #                           ├── ...\n",
    "    #                      ├── subfolder1\n",
    "    #                           ├── frame000\n",
    "    #                           ├── frame001\n",
    "    #                           ├── ...\n",
    "    #                       ├── ...\n",
    "    #                       \n",
    "    # vimeo90k_dataset:  1. clip name; 2. frame number; 3. number of frames; 4. tamaño de la imágen \n",
    "    #  00001/0001 7 (256,448,3)\n",
    "    dataroot_gt: datasets/REDS/train_sharp/train/train_sharp\n",
    "    # path a las imágenes originales\n",
    "    dataroot_lq: datasets/REDS/train_blur_bicubic/train/train_blur_bicubic/X4\n",
    "    # path a las imágenes en baja calidad\n",
    "    meta_info_file: basicsr/data/meta_info/meta_info_REDS4_test_GT.txt\n",
    "    # selección de sub-carpetas con las que se ejecutara EDVR\n",
    "    io_backend:\n",
    "      type: disk\n",
    "    # hay tres opciones para la ejecución disk, LMDB o memcached, solo se ha usado disk para los experimentos\n",
    "    cache_data: false\n",
    "    num_frame: 5\n",
    "    # número de frames\n",
    "    padding: replicate\n",
    "    # replicate o reflection_circle, son dos técnicas para conseguir que durante el procesamiento el tamaño de las \n",
    "    # imagenes no cambien.\n",
    "```   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "network_g:\n",
    "  type: EDVR\n",
    "  # tipo de arquitectura que se usa, solo usaremos EDVR\n",
    "  num_in_ch: 3\n",
    "  # número de canales de entradas de inputs \n",
    "  num_out_ch: 3\n",
    "  # número de canales de salidas de inputs \n",
    "  num_feat: 128\n",
    "  # número de canales intermedios \n",
    "  num_frame: 5\n",
    "  # número de frames\n",
    "  deformable_groups: 8\n",
    "  num_extract_block: 5\n",
    "  num_reconstruct_block: 40\n",
    "  center_frame_idx: ~\n",
    "  hr_in: false\n",
    "  with_predeblur: true\n",
    "  # tenemos la opción de activar o desactivar la opción de desemborronado previo\n",
    "  with_tsa: true\n",
    "  # tenemos la opción de activar o desactivar la opción de TSA de fusión de frames\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "path:\n",
    "  pretrain_network_g: experiments/pretrained_models/EDVR/EDVR_L_x4_SRblur_REDS_official-983d7b8e.pth\n",
    "  # path al modelo pre-entrenado\n",
    "  strict_load_g: true\n",
    "  # si solo queremos cargar el modelo pre-entrenado\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "val:\n",
    "  save_img: true\n",
    "  # decide si se guardan las imágenes durante la validación\n",
    "  suffix: ~  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ```yaml\n",
    " metrics:\n",
    " # métricas extra que calculan el PSNR(Peak Signal-to-Noise Ratio)\n",
    "    psnr: y\n",
    "      type: calculate_psnr\n",
    "      crop_border: 0\n",
    "      test_y_channel: false\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN AND TEST<a name=\"id9\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "Ambas opciones tienen varias opciones de ejecución, aunque en mi caso solo se ha experimentado con una debida a las limitaciones hardware.\n",
    "La versión que se ha usado es la de una sola GPU, también se puede trabajar con múltiples GPU(4 y 8), y por último  se puede trabajar en modo Slurm con 1, 4 o 8 GPU.\n",
    "\n",
    "La forma de ejecutar el script es muy parecida, pero para las versiones multiGPU hay que usar más parámetros opcionales.\n",
    "\n",
    "La única diferencia en este apartado respecto al el modo train o test se corresponde al path de archivos .yml que analizamos anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN 1 GPU<a name=\"id10\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "```bash\n",
    "PYTHONPATH=\"./:${PYTHONPATH}\" \\\n",
    "CUDA_VISIBLE_DEVICES=0 \\\n",
    "python basicsr/train.py -opt options/train/EDVR/train_EDVR_L_x4_SR_REDS.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 1 GPU<a name=\"id11\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "```bash\n",
    "PYTHONPATH=\"./:${PYTHONPATH}\" \\\n",
    "CUDA_VISIBLE_DEVICES=0 \\\n",
    "python basicsr/test.py -opt options/test/EDVR/test_EDVR_L_x4_SRblur_REDS.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 8 GPU<a name=\"id12\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "```bash\n",
    "PYTHONPATH=\"./:${PYTHONPATH}\" \\\n",
    "CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 \\\n",
    "python -m torch.distributed.launch --nproc_per_node=8 --master_port=4321 basicsr/test.py -opt options/test/EDVR/test_EDVR_L_x4_SRblur_REDS.yml --launcher pytorch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 1 GPU Slurm<a name=\"id13\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "```bash\n",
    "PYTHONPATH=\"./:${PYTHONPATH}\" \\\n",
    "GLOG_vmodule=MemcachedClient=-1 \\\n",
    "srun -p [partition] --mpi=pmi2 --job-name=test --gres=gpu:1 --ntasks=1 --ntasks-per-node=1 --cpus-per-task=6 --kill-on-bad-exit=1 \\\n",
    "python -u basicsr/test.py -opt options/test/EDVR/test_EDVR_L_x4_SRblur_REDS.yml --launcher=\"slurm\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJECUCIÓN<a name=\"id14\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se ejecutará una de las versiones del dataset REDS.\n",
    "Si se ha seguido los pasos descritos anteriormente y se tienen los dataset descargados correctamente use las líneas que vienen por defecto.\n",
    "Si no, elimine el # en la línea comentada y comente la que no estaba comentada, así usara los recursos proporcionados en mi repositorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!PYTHONPATH=\"./:${PYTHONPATH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python ../basicsr/test.py -opt miniConjunto/test_EDVR_L_x4_SRblur_REDS.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disable distributed.\n",
      "Path already exists. Rename it to /home/edvr/edvr/BasicSR/results/EDVR_L_x4_REDS_SRblur_official_archived_20210223_231639\n",
      "2021-02-23 23:16:39,255 INFO: \n",
      "                ____                _       _____  ____\n",
      "               / __ ) ____ _ _____ (_)_____/ ___/ / __ \\\n",
      "              / __  |/ __ `// ___// // ___/\\__ \\ / /_/ /\n",
      "             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/\n",
      "            /_____/ \\__,_//____//_/ \\___//____//_/ |_|\n",
      "     ______                   __   __                 __      __\n",
      "    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /\n",
      "   / / __ / __ \\ / __ \\ / __  /  / /   / / / // ___// //_/  / /\n",
      "  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/\n",
      "  \\____/ \\____/ \\____/ \\____/  /_____/\\____/ \\___//_/|_|  (_)\n",
      "    \n",
      "Version Information: \n",
      "\tBasicSR: 1.2.0+1464d8e\n",
      "\tPyTorch: 1.7.0\n",
      "\tTorchVision: 0.8.1\n",
      "2021-02-23 23:16:39,255 INFO: \n",
      "  name: EDVR_L_x4_REDS_SRblur_official\n",
      "  model_type: EDVRModel\n",
      "  scale: 4\n",
      "  num_gpu: 4\n",
      "  manual_seed: 0\n",
      "  datasets:[\n",
      "    test:[\n",
      "      name: REDS4\n",
      "      type: VideoTestDataset\n",
      "      dataroot_gt: datasets/REDS/train_sharp/train/train_sharp\n",
      "      dataroot_lq: datasets/REDS/train_blur_bicubic/train/train_blur_bicubic/X4\n",
      "      meta_info_file: basicsr/data/meta_info/meta_info_REDS4_test_GT.txt\n",
      "      io_backend:[\n",
      "        type: disk\n",
      "      ]\n",
      "      cache_data: False\n",
      "      num_frame: 5\n",
      "      padding: replicate\n",
      "      phase: test\n",
      "      scale: 4\n",
      "    ]\n",
      "  ]\n",
      "  network_g:[\n",
      "    type: EDVR\n",
      "    num_in_ch: 3\n",
      "    num_out_ch: 3\n",
      "    num_feat: 128\n",
      "    num_frame: 5\n",
      "    deformable_groups: 8\n",
      "    num_extract_block: 5\n",
      "    num_reconstruct_block: 40\n",
      "    center_frame_idx: None\n",
      "    hr_in: False\n",
      "    with_predeblur: True\n",
      "    with_tsa: True\n",
      "  ]\n",
      "  path:[\n",
      "    pretrain_network_g: experiments/pretrained_models/EDVR/EDVR_L_x4_SRblur_REDS_official-983d7b8e.pth\n",
      "    strict_load_g: True\n",
      "    root: /home/edvr/edvr/BasicSR\n",
      "    results_root: /home/edvr/edvr/BasicSR/results/EDVR_L_x4_REDS_SRblur_official\n",
      "    log: /home/edvr/edvr/BasicSR/results/EDVR_L_x4_REDS_SRblur_official\n",
      "    visualization: /home/edvr/edvr/BasicSR/results/EDVR_L_x4_REDS_SRblur_official/visualization\n",
      "  ]\n",
      "  val:[\n",
      "    save_img: True\n",
      "    suffix: None\n",
      "    metrics:[\n",
      "      psnr:[\n",
      "        type: calculate_psnr\n",
      "        crop_border: 0\n",
      "        test_y_channel: False\n",
      "      ]\n",
      "    ]\n",
      "  ]\n",
      "  is_train: False\n",
      "  dist: False\n",
      "  rank: 0\n",
      "  world_size: 1\n",
      "\n",
      "2021-02-23 23:16:39,255 INFO: Generate data info for VideoTestDataset - REDS4\n",
      "2021-02-23 23:16:39,256 INFO: Dataset VideoTestDataset - REDS4 is created.\n",
      "2021-02-23 23:16:39,256 INFO: Number of test images in REDS4: 400\n",
      "2021-02-23 23:16:45,105 INFO: Network: DataParallel - EDVR, with parameters: 23,306,851\n",
      "2021-02-23 23:16:45,105 INFO: EDVR(\n",
      "  (predeblur): PredeblurModule(\n",
      "    (conv_first): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (stride_conv_l2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (stride_conv_l3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (resblock_l3): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (resblock_l2_1): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (resblock_l2_2): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (resblock_l1): ModuleList(\n",
      "      (0): ResidualBlockNoBN(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): ResidualBlockNoBN(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): ResidualBlockNoBN(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): ResidualBlockNoBN(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): ResidualBlockNoBN(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (conv_1x1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (feature_extraction): Sequential(\n",
      "    (0): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv_l2_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv_l2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv_l3_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv_l3_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pcd_align): PCDAlignment(\n",
      "    (offset_conv1): ModuleDict(\n",
      "      (l3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (l2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (l1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (offset_conv2): ModuleDict(\n",
      "      (l3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (l2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (l1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (offset_conv3): ModuleDict(\n",
      "      (l2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (l1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (dcn_pack): ModuleDict(\n",
      "      (l3): DCNv2Pack(\n",
      "        (conv_offset): Conv2d(128, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (l2): DCNv2Pack(\n",
      "        (conv_offset): Conv2d(128, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (l1): DCNv2Pack(\n",
      "        (conv_offset): Conv2d(128, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (feat_conv): ModuleDict(\n",
      "      (l2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (l1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (cas_offset_conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (cas_offset_conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (cas_dcnpack): DCNv2Pack(\n",
      "      (conv_offset): Conv2d(128, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (fusion): TSAFusion(\n",
      "    (temporal_attn1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (temporal_attn2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (feat_fusion): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (max_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (avg_pool): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
      "    (spatial_attn1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (spatial_attn2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (spatial_attn3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (spatial_attn4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (spatial_attn5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (spatial_attn_l1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (spatial_attn_l2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (spatial_attn_l3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (spatial_attn_add1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (spatial_attn_add2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "  )\n",
      "  (reconstruction): Sequential(\n",
      "    (0): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (18): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (19): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (20): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (21): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (22): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (23): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (24): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (25): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (26): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (27): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (28): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (29): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (30): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (31): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (32): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (33): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (34): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (35): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (36): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (37): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (38): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (39): ResidualBlockNoBN(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (upconv1): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (upconv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pixel_shuffle): PixelShuffle(upscale_factor=2)\n",
      "  (conv_hr): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      ")\n",
      "2021-02-23 23:16:45,105 INFO: Loading EDVR model from experiments/pretrained_models/EDVR/EDVR_L_x4_SRblur_REDS_official-983d7b8e.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-23 23:16:45,810 INFO: Model [EDVRModel] is created.\n",
      "2021-02-23 23:16:45,810 INFO: Testing REDS4...\n",
      "2021-02-23 23:16:45,810 WARNING: nondist_validation is not implemented. Run dist_validation.\n",
      "Test 020:100/100: 100%|████████████████████| 400/400 [03:32<00:00,  1.88frame/s]\n",
      "2021-02-23 23:20:18,483 INFO: Validation REDS4\n",
      "\t # psnr: 28.8819\t # 000: 27.3231\t # 011: 29.4919\t # 015: 31.2684\t # 020: 27.4444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ../basicsr/test.py -opt options/test/EDVR/test_EDVR_L_x4_SRblur_REDS.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEMOSTRACIÓN<a name=\"id15\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ejemplos/00000004.png\">\n",
    "\n",
    "### Imagen original en baja calidad de REDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ejemplos/00000004_EDVR_L_x4_REDS_SRblur_official.png\">\n",
    "\n",
    "### Imagen procesada por EDVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ejemplos/00000009.png\">\n",
    "\n",
    "### Imagen original en baja clidad de REDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ejemplos/00000009_EDVR_L_x4_REDS_SRblur_official.png\">\n",
    "\n",
    "### Imagen procesada por EDVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PYTHONPATH=\"./:${PYTHONPATH}\"\n",
    "CUDA_VISIBLE_DEVICES=0\n",
    "python basicsr/test.py -opt options/test/EDVR/test_EDVR_L_x4_SR_Mio.yml\n",
    "\n",
    "PYTHONPATH=\"./:${PYTHONPATH}\"\n",
    "CUDA_VISIBLE_DEVICES=0\n",
    "python basicsr/test.py -opt options/test/EDVR/test_EDVR_L_x4_SR_NO_INTERFAZ.yml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
