{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estudio de funcionamiento de EDVR, herramienta de superresolución de vídeos\n",
    "## TFG del Grado en Ingeniería Informática en la Universidad de Burgos. Curso 2020-21\n",
    "\n",
    "Realizado por:\n",
    "*  Gonzalo Murillo Montes \n",
    "\n",
    "Tutores:\n",
    "*  Pedro Latorre Carmona\n",
    "*  César Ignacio Garcıa Osorio\n",
    "\n",
    "```\n",
    "@misc{wang2020basicsr,\n",
    "  author =       {Xintao Wang and Ke Yu and Kelvin C.K. Chan and\n",
    "                  Chao Dong and Chen Change Loy},\n",
    "  title =        {BasicSR},\n",
    "  howpublished = {\\url{https://github.com/xinntao/BasicSR}},\n",
    "  year =         {2020}\n",
    "}\n",
    "```\n",
    "Xintao Wang, Kelvin C.K. Chan, Ke Yu, Chao Dong, &amp; Chen Change Loy. (2019, May 7). EDVR: Video Restoration with Enhanced Deformable Convolutional Networks [PDF]. Ithaca, New York: Cornell University."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ¿NTIRE19 Challenge?\n",
    "\n",
    "New Trends in Image Restoration and Enhancement workshop and challenges on image and video restoration and enhancement.\n",
    "Proponen diversos retos en las áreas de la restauración de imágenes y vídeos y los participntes compiten para obtener los mejores resultados.\n",
    "\n",
    "EDVR es la solución ganadora del NTIRE19 Challenge en la categoría de super-resolucion de vídeos, centrada en dos aspectos:\n",
    "\n",
    "* Alienación de múltiples frames con mucho movimiento.\n",
    "* Fusion de frames con distintos movimientos y partes borrosas. \n",
    "\n",
    "EDVR ganó en las 4 pruebas relacionadas con vídeos con amplio margen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ¿Qué es EDVR?\n",
    "\n",
    "EDVR es el acrónimo de Enhanced Deformable convolutions Video Restoration, es una herramienta conteniada en BasicSR, centrada en la super-resolución y desemborronamiento de vídeos.\n",
    "\n",
    "Está basada en dos principios el PCD (Pyramid,\n",
    "Cascading and Deformable convolutions) y el TSA (Temporal and Spatial Attention)\n",
    "\n",
    "* PCD: usa convoluciones deformables para agrupar píxeles cercanos, usando una estructura piramidal invertida empezando a pequeña escala y progresivamente aumentando, junto a esto se aplica un efecto cascada para mejorar resultados. \n",
    "* TSA: es um módulo de fusion que agrega información comparando frames con sus anteriores y posteriores, toda esa información luego se usa en todos los frames.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Cambiar imágen \n",
    "!-[image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esta parte coreesponde con la demostración y análisis de cómo funciona EDVR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero es seleccionar los datasets o imágenes con las que se va a trabajar, si se quisiese usar un vídeo primero habría que generar la secuencia de frames y las imágenes en baja calidad.\n",
    "\n",
    "Una vez hecho esto hay que crear un fichero .yml con las especificaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: EDVR_L_x4_REDS_SRblur_official\r\n",
      "model_type: EDVRModel\r\n",
      "scale: 4\r\n",
      "num_gpu: 4 \r\n",
      "manual_seed: 0\r\n",
      "\r\n",
      "# name:os cambiar el nombre que le queremos dar a la ejecución\r\n",
      "# model:el modelo siempre será el mismo ya que solo trabajamos con EDVR en BasicSR.\r\n",
      "# scale: es la escala de la salida respecto a la entrada, el upsampling ratio.\r\n",
      "# num_gpu: en todas nuestras ejecuciones el número de Gpu's es una por nustras limitaciones hardware, que se indica por \r\n",
      "#          parametro.\r\n",
      "\r\n",
      "datasets:\r\n",
      "  test:\r\n",
      "    name: REDS4\r\n",
      "    type: VideoTestDataset\r\n",
      "    dataroot_gt: datasets/REDS/train_sharp/train/train_sharp\r\n",
      "    dataroot_lq: datasets/REDS/train_blur_bicubic/train/train_blur_bicubic/X4\r\n",
      "    meta_info_file: basicsr/data/meta_info/meta_info_REDS4_test_GT.txt\r\n",
      "    io_backend:\r\n",
      "      type: disk\r\n",
      "\r\n",
      "    cache_data: false\r\n",
      "    num_frame: 5\r\n",
      "    padding: replicate\r\n",
      "\r\n",
      "# name: el nombre del dataset.\r\n",
      "# type: es el tipo de dataset que se usa, depende de la estructura de los dataset, en nuestros casos se usan dos:\r\n",
      "#     video_test_dataset: \r\n",
      "#                            dataroot\r\n",
      "#                            ├── subfolder1\r\n",
      "#                                ├── frame000\r\n",
      "#                                ├── frame001\r\n",
      "#                                ├── ...\r\n",
      "#                            ├── subfolder1\r\n",
      "#                                ├── frame000\r\n",
      "#                                ├── frame001\r\n",
      "#                                ├── ...\r\n",
      "#                            ├── ...\r\n",
      "#\r\n",
      "#    vimeo90k_dataset:  1. clip name; 2. frame number; 3. image shape, seperated by a white space.\r\n",
      "# \r\n",
      "# dataroot_gt: path a las imágenes originales.\r\n",
      "# dataroot_lq: path a las imágenes en baja calidad.\r\n",
      "# meta_info_file: el fichero con la estructura de los datasets.\r\n",
      "# io_backend: Hay tres opciones para la ejecución disk, LMDB o memcached, solo se ha usdo disk para nustros experimentos.\r\n",
      "# padding: replicate o reflection_circle, son dos técnicas para conseguir que durante el procesamiento el tamaño de las \r\n",
      "#          imágenes no cambie.\r\n",
      "\r\n",
      "network_g:\r\n",
      "  type: EDVR\r\n",
      "  num_in_ch: 3\r\n",
      "  num_out_ch: 3\r\n",
      "  num_feat: 128\r\n",
      "  num_frame: 5\r\n",
      "  deformable_groups: 8\r\n",
      "  num_extract_block: 5\r\n",
      "  num_reconstruct_block: 40\r\n",
      "  center_frame_idx: ~\r\n",
      "  hr_in: false\r\n",
      "  with_predeblur: true\r\n",
      "  with_tsa: true\r\n",
      "\r\n",
      "# type: tipo de arquitectura que se usa, solo usaremos EDVR.\r\n",
      "# with_predeblur: tenemos la opción de activar o desactivar la opción de desemborronado previo. \r\n",
      "# with_tsa: tenemos la opción de activar o desactivar la opción de TSA de fusion de frames, aunque es una de las \r\n",
      "#           funcionalidades básicas de EDVR.\r\n",
      "\r\n",
      "path:\r\n",
      "  pretrain_network_g: experiments/pretrained_models/EDVR/EDVR_L_x4_SRblur_REDS_official-983d7b8e.pth\r\n",
      "  strict_load_g: true\r\n",
      "\r\n",
      "#  pretrain_network_g: path al modelo preentrenado.\r\n",
      "#  strict_load_g: tenemos la opción de usarlo o no.\r\n",
      "\r\n",
      "val:\r\n",
      "  save_img: true\r\n",
      "  suffix: ~  \r\n",
      "  \r\n",
      "# save_img: decide si se guardan las imágenes durante la validación.\r\n",
      "\r\n",
      "\r\n",
      "  metrics:\r\n",
      "    psnr: y\r\n",
      "      type: calculate_psnr\r\n",
      "      crop_border: 0\r\n",
      "      test_y_channel: false\r\n",
      "\r\n",
      "# Metricas extra que calculan el PSNR(Peak Signal-to-Noise Ratio)"
     ]
    }
   ],
   "source": [
    "!cat options/test/EDVR/configuracion.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estructura de los datasets?¿"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test:\n",
    "\n",
    "Ambas opciones tienen varias opcioines de ejecución, aunque en nuestro caso solo se ha experimentado con una debeida a las limitaciones hardware.\n",
    "La versión que se ha usado es la de una sola GPU, también se puede trabajar con múltiples GPU's(4 y 8), y por último también se puede trabajar en modo Slurm con 1, 4 o 8 GPU's."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
